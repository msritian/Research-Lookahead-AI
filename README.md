# Research-Lookahead-AI: Sequential Trading Agent Evaluation

A robust environment for evaluating Large Language Models (LLMs) as sequential traders in historical prediction markets (Kalshi). This system goes beyond static accuracy, testing an agent's ability to manage a portfolio, timing, and evolving context over time.

## ğŸŒŸ Key Features

*   **Sequential Decision Making**: Agents must Buy, Sell, or Hold over a 14-day period (configurable).
*   **Time-Travel Simulation**:
    *   **Strict Temporal Provenance**: The agent only sees data (Prices, News) available *up to* the current simulation step.
    *   **Chain-of-Memory**: Reasoning and "Journal" entries are passed from Day N to Day N+1, simulating continuous thought.
*   **Real Data Integration**:
    *   **Kalshi API**: Fetches historical trade data (aggregated to OHLC). *Note: Order Book is estimated via Last Price.*
    *   **Context/News Engine**: Flexible provider supporting **Exa**, **Tavily**, and **Web Scraping** to give the agent qualitative context (e.g., "Fed Chair Powell spoke today...").
*   **Portfolio Management**: Tracks Cash, Positions, PnL per market, and enforces valid trades (no short-selling without holdings).
*   **Structure Output**: LLMs are forced to output strict JSON with `action`, `quantity`, `belief_probability`, `reasoning`, and `journal`.

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ main.py                 # Entry point for Full Simulation
â”œâ”€â”€ verify.py               # Quick verification loop (Mock data)
â”œâ”€â”€ run_simulation.sh       # Helper script to manage Keys & Config
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ src/
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ llm_agent.py    # Core Agent Logic (Prompting, Parsing)
    â”‚   â”œâ”€â”€ openai_provider.py # OpenAI API Wrapper
    â”‚   â””â”€â”€ prompts.py      # System & User Templates (Dynamic)
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ environment.py  # Simulation Loop (Time, Data, Logging)
    â”‚   â”œâ”€â”€ portfolio.py    # Financial State Machine
    â”‚   â””â”€â”€ types.py        # Pydantic Models (Action, Observation)
    â””â”€â”€ data_loaders/
        â”œâ”€â”€ kalshi.py       # Market Data Provider
        â””â”€â”€ context.py      # News/Web Data Provider (Exa, Tavily)
```

## ğŸš€ Getting Started

### 1. Prerequisites
- Python 3.9+
- API Keys (Optional but recommended for Real execution):
    - `OPENAI_API_KEY`: For the Agent logic.
    - `EXA_API_KEY` or `TAVILY_API_KEY`: For news context.
    - `KALSHI_API_KEY`: For market data (referenced but public data often accessible without).

### 2. Installation
```bash
pip install -r requirements.txt
```

### 3. Running a Simulation
The easiest way is to use the interactive helper script:

```bash
./run_simulation.sh
```

1.  It will prompt you for your API Keys (temporarily exports them).
2.  Choose **Option 2 (Full Simulation)**.
3.  Enter the **Ticker** (e.g., `FED-RATE-CUT`) and the **Question** (e.g., "Will the Fed cut interest rates?").
4.  Sit back! The agent will trade for the specified duration.

### 4. Direct Usage (Advanced)
```bash
export OPENAI_API_KEY="sk-..."
python3 main.py \
  --ticker "FED-RATE-CUT" \
  --question "Will the Fed cut rates?" \
  --start-date "2024-03-01" \
  --days 14
```

## ğŸ§  Agent Logic: The "Journal" Interface
To solve the "context window overflow" problem in long simulations, this agent uses a **Journaling** mechanism.
- **Input**: Day N Context + [PREVIOUS JOURNAL] (Summary of Days 0..N-1).
- **Output**: Action + Reasoning + **[NEW JOURNAL ENTRY]**.
- This forces the model to summarize critical data points *as it goes*, preserving long-term memory without re-reading 14 days of raw news.

## ğŸ“Š Evaluation
Logs are saved to `logs/experiment_YYYYMMDD_HHMMSS.jsonl`.
Each line contains:
- Timestamp
- Market Prices
- Portfolio Value
- Agent Action & Reasoning

## ğŸ›  Extensibility
- **New LLMs**: Implement `src.core.llm_interface.LLMProvider`.
- **New Data**: Implement `src.data_loaders.market.DataProvider`.

## ğŸ”® Future Goals

The ultimate vision for this project is to benchmark and improve agentic capabilities in complex, evolving environments. Key areas of focus:

1.  **Open Source VLMs**: Evaluate and integrate Vision-Language Models (e.g., LLaVA, Yi-VL) to directly process charts and visual market data.
2.  **Visual World Modeling**: Move beyond text-based context to agents that build a "Visual World Model" of market dynamics.
3.  **Continual Learning**: Implement mechanisms for agents to update their weights or long-term memory store *post-training* based on simulation outcomes (Regret minimization).
4.  **Pre-training & Post-training**: Use the logs generated by this benchmark to create fine-tuning datasets for specialized "Trader Experts".
5.  **Spatial Grounding**: Improve the agent's ability to spatially locate and reason about specific signals within high-density visual info (e.g., specific trend lines on a chart or heatmap regions).
6.  **Next Scene Prediction & Latent Representations**: Developing world models that can predict future market "scenes" in latent space, allowing the agent to anticipate shifts before they are reflected in raw data.

### ğŸŒ Broader Applications

While the current focus is on prediction markets like Kalshi, the sequential agentic framework is designed to generalize to other high-stakes domains:
- **Climate & Environment**: Predicting ecosystem shifts or policy impacts.
- **Natural Calamities & Disasters**: Sequential modeling for early warning systems and resource allocation.
- **Supply Chain & Logistics**: Navigating global disruptions in real-time.
- **Public Health**: Anticipating epidemic trends and policy effectiveness.